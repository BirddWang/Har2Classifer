{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models.video as video_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"harmonization_public.pt\", map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, conditional_ch=0, num_lvs=4, base_ch=16, final_act='noact'):\n",
    "        super().__init__()\n",
    "        self.final_act = final_act\n",
    "        self.in_conv = nn.Conv2d(in_ch, base_ch, 3, 1, 1)\n",
    "\n",
    "        self.down_convs = nn.ModuleList()\n",
    "        self.down_samples = nn.ModuleList()\n",
    "        self.up_samples = nn.ModuleList()\n",
    "        self.up_convs = nn.ModuleList()\n",
    "        for lv in range(num_lvs):\n",
    "            ch = base_ch * (2 ** lv)\n",
    "            self.down_convs.append(ConvBlock2d(ch + conditional_ch, ch * 2, ch * 2))\n",
    "            self.down_samples.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "            self.up_samples.append(Upsample(ch * 4))\n",
    "            self.up_convs.append(ConvBlock2d(ch * 4, ch * 2, ch * 2))\n",
    "        bottleneck_ch = base_ch * (2 ** num_lvs)\n",
    "        self.bottleneck_conv = ConvBlock2d(bottleneck_ch, bottleneck_ch * 2, bottleneck_ch * 2)\n",
    "        self.out_conv = nn.Sequential(nn.Conv2d(base_ch * 2, base_ch, 3, 1, 1),\n",
    "                                      nn.LeakyReLU(0.1),\n",
    "                                      nn.Conv2d(base_ch, out_ch, 3, 1, 1))\n",
    "\n",
    "    def forward(self, in_tensor, condition=None):\n",
    "        encoded_features = []\n",
    "        x = self.in_conv(in_tensor)\n",
    "        for down_conv, down_sample in zip(self.down_convs, self.down_samples):\n",
    "            if condition is not None:\n",
    "                feature_dim = x.shape[-1]\n",
    "                down_conv_out = down_conv(torch.cat([x, condition.repeat(1, 1, feature_dim, feature_dim)], dim=1))\n",
    "            else:\n",
    "                down_conv_out = down_conv(x)\n",
    "            x = down_sample(down_conv_out)\n",
    "            encoded_features.append(down_conv_out)\n",
    "        x = self.bottleneck_conv(x)\n",
    "        for encoded_feature, up_conv, up_sample in zip(reversed(encoded_features),\n",
    "                                                       reversed(self.up_convs),\n",
    "                                                       reversed(self.up_samples)):\n",
    "            x = up_sample(x, encoded_feature)\n",
    "            x = up_conv(x)\n",
    "        x = self.out_conv(x)\n",
    "        if self.final_act == 'sigmoid':\n",
    "            x = torch.sigmoid(x)\n",
    "        elif self.final_act == \"relu\":\n",
    "            x = torch.relu(x)\n",
    "        elif self.final_act == 'tanh':\n",
    "            x = torch.tanh(x)\n",
    "        else:\n",
    "            x = x\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvBlock2d(nn.Module):\n",
    "    def __init__(self, in_ch, mid_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, mid_ch, 3, 1, 1),\n",
    "            nn.InstanceNorm2d(mid_ch),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(mid_ch, out_ch, 3, 1, 1),\n",
    "            nn.InstanceNorm2d(out_ch),\n",
    "            nn.LeakyReLU(0.1)\n",
    "        )\n",
    "\n",
    "    def forward(self, in_tensor):\n",
    "        return self.conv(in_tensor)\n",
    "\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, in_ch):\n",
    "        super().__init__()\n",
    "        out_ch = in_ch // 2\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, 1, 1),\n",
    "            nn.InstanceNorm2d(out_ch),\n",
    "            nn.LeakyReLU(0.1)\n",
    "        )\n",
    "\n",
    "    def forward(self, in_tensor, encoded_feature):\n",
    "        up_sampled_tensor = F.interpolate(in_tensor, size=None, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        up_sampled_tensor = self.conv(up_sampled_tensor)\n",
    "        return torch.cat([encoded_feature, up_sampled_tensor], dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_r3d_for_5_channels(model_name='r3d_18', num_classes=2):\n",
    "    \"\"\"Loads a 3D ResNet model and modifies its first layer for 5 input channels.\"\"\"\n",
    "    # Load the specified ResNet3D model, without pre-trained weights initially\n",
    "    if model_name == 'r3d_18':\n",
    "        model = video_models.r3d_18(weights=None)\n",
    "    elif model_name == 'mc3_18': # Another option\n",
    "         model = video_models.mc3_18(weights=None)\n",
    "    # Add more models here if needed (r3d_34, r3d_50...)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model name: {model_name}\")\n",
    "\n",
    "    # Get parameters of the original first convolutional layer (stem[0])\n",
    "    original_conv = model.stem[0]\n",
    "    original_out_channels = original_conv.out_channels\n",
    "    original_kernel_size = original_conv.kernel_size\n",
    "    original_stride = original_conv.stride\n",
    "    original_padding = original_conv.padding\n",
    "    original_bias = original_conv.bias is not None # Check if bias exists\n",
    "\n",
    "    # Create the new first convolutional layer with 5 input channels\n",
    "    new_first_conv = nn.Conv3d(in_channels=5,\n",
    "                               out_channels=original_out_channels,\n",
    "                               kernel_size=original_kernel_size,\n",
    "                               stride=original_stride,\n",
    "                               padding=original_padding,\n",
    "                               bias=original_bias) # Keep bias setting consistent\n",
    "\n",
    "    # Replace the original first layer with the new one\n",
    "    model.stem[0] = new_first_conv\n",
    "\n",
    "    # --- Modify the final fully connected layer for the desired number of output classes ---\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes) # Example: 2 classes for Autism vs Control\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape:  torch.Size([1, 1, 192, 224])\n"
     ]
    }
   ],
   "source": [
    "input_ch = 1\n",
    "beta_dim = 5\n",
    "input_height = 192\n",
    "input_width = 224\n",
    "batch_size = 1\n",
    "dummy_input = torch.randn(batch_size, input_ch, input_height, input_width)\n",
    "print(\"Input Shape: \", dummy_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta Shape:  torch.Size([1, 5, 192, 224])\n"
     ]
    }
   ],
   "source": [
    "beta_encoder = UNet(in_ch=1, out_ch=5, base_ch=8, final_act='none')\n",
    "beta_encoder.load_state_dict(checkpoint['beta_encoder']) \n",
    "\n",
    "beta_encoder.eval()\n",
    "with torch.no_grad():\n",
    "    beta = beta_encoder(dummy_input)\n",
    "    print(\"Beta Shape: \", beta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VideoResNet(\n",
       "  (stem): BasicStem(\n",
       "    (0): Conv3d(5, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2), padding=(1, 3, 3), bias=False)\n",
       "    (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth = 192\n",
    "num_classes = 2\n",
    "\n",
    "r3d_model = modify_r3d_for_5_channels(model_name='r3d_18', num_classes=num_classes)\n",
    "r3d_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R3D Input Shape:  torch.Size([1, 5, 192, 192, 224])\n"
     ]
    }
   ],
   "source": [
    "dummy_resnet_input = torch.randn(batch_size, beta_dim, depth, input_height, input_width)\n",
    "print(\"R3D Input Shape: \", dummy_resnet_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R3D Output Shape:  torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    r3d_output = r3d_model(dummy_resnet_input)\n",
    "    print(\"R3D Output Shape: \", r3d_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
